{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <HR>Creation of Geographical Features for Wildfires Incidents<HR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'GeographicalFeaturesGenerator' class to extract the environmental features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeographicalFeaturesGenerator:\n",
    "    \"\"\"FeaturesGenerator to generate geographical features.\n",
    "    \n",
    "    It generates the features like land_type, district, federal_subject of fire incident area and \n",
    "    distance from forest, city. Also, number of forest/field/cities within the radius.\n",
    "    \n",
    "    Russian-cities Data Source:\n",
    "    https://github.com/pensnarik/russian-cities\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, wildfire_data, forest_data, field_data, land_data, nature_forest_data, cities_data):\n",
    "        self.wildfire_data = wildfire_data\n",
    "        self.forest_data = forest_data\n",
    "        self.field_data = field_data \n",
    "        self.land_data = land_data \n",
    "        self.nature_forest_data = nature_forest_data\n",
    "        self.cities_data = cities_data\n",
    "    \n",
    "    def _predict_label(self, df_train, df_test, label=None):    \n",
    "        \"\"\"predict the label(land_type,district..) for data points in df_test\"\"\"\n",
    "        #train k-nearest neighbors classifier \n",
    "        neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "        X, y = df_train[['longitude', 'latitude']], df_train[label]\n",
    "        neigh.fit(X, y)\n",
    "        #predict the label for wildfire incidents\n",
    "        pred_label = neigh.predict(df_test[['longitude', 'latitude']])\n",
    "        return pred_label\n",
    "    \n",
    "    def _get_dst(self, df_train, df_test):\n",
    "        \"\"\"find the minimum distance from data points in df_test to nearest data point in df_train\"\"\"\n",
    "        #train NearestNeighbors(Unsupervised learner)\n",
    "        neigh = NearestNeighbors(1)\n",
    "        neigh.fit(df_train[['longitude', 'latitude']])\n",
    "        #find the K-neighbors of points in df_test\n",
    "        distances, indices = neigh.kneighbors(df_test[['longitude', 'latitude']])\n",
    "        return distances\n",
    "    \n",
    "    def _get_info_radius(self, df_train, df_test, radii, _type):\n",
    "        \"\"\"get number of forest/field/cities within the radius\"\"\"\n",
    "        result = pd.DataFrame()\n",
    "        #train NearestNeighbors(Unsupervised learner)\n",
    "        neigh = NearestNeighbors()\n",
    "        neigh.fit(df_train[['longitude', 'latitude']])\n",
    "        #find\n",
    "        for radius in radii:\n",
    "            distances, indices = neigh.radius_neighbors(df_test[['longitude', 'latitude']], radius=radius)\n",
    "            count = np.vectorize(len)(distances)\n",
    "            has_type = np.where(count > 0, 1, 0)\n",
    "            result['has_{0}_radius_{1}'.format(_type,radius)] = has_type\n",
    "            result['num_{0}_radius_{1}'.format(_type,radius)] = count\n",
    "        return result\n",
    "    \n",
    "    def _get_event_count_lastyear(self, wildfire_data):\n",
    "        \"\"\" \"\"\"\n",
    "        radii = [1.0, 1.5, 2, 2.5]\n",
    "        wildfire_data['year'] = wildfire_data.date.dt.year\n",
    "        wildfire_data['month'] = wildfire_data.date.dt.month\n",
    "        start_year = wildfire_data.year.min()\n",
    "        end_year = wildfire_data.year.max()\n",
    "        result = pd.DataFrame()\n",
    "        for radius in radii:\n",
    "            temp = pd.Series(np.zeros((wildfire_data.shape[0])))\n",
    "            for cur_year, month in itertools.product(range(start_year+1,end_year+1),range(1,13)):\n",
    "                prev_year = cur_year - 1\n",
    "                mask_prev = (wildfire_data.year<=prev_year)&(wildfire_data.month==month)\n",
    "                mask_cur = (wildfire_data.year==cur_year)&(wildfire_data.month==month)\n",
    "                if sum(mask_prev)!=0 and sum(mask_cur)!=0:\n",
    "                    #train\n",
    "                    neigh = NearestNeighbors(radius=radius)\n",
    "                    neigh.fit(wildfire_data[mask_prev][['longitude', 'latitude']])\n",
    "                    #find\n",
    "                    distances, indices = neigh.radius_neighbors(wildfire_data[mask_cur][['longitude', 'latitude']])\n",
    "                    count = np.vectorize(len)(distances)\n",
    "                    #\n",
    "                    temp.loc[mask_cur] = count\n",
    "            result['num_event_lastyear_radius_{0}'.format(radius)] = temp \n",
    "        return result\n",
    "\n",
    "    def start(self):\n",
    "        print(\"=\"*5,\"Features Extraction has started\",\"=\"*5)\n",
    "        start = time.time()\n",
    "        #predict land_type, federal_subject, district for fire incident area\n",
    "        self.wildfire_data['land_type'] = self._predict_label(self.land_data, self.wildfire_data, label='land_type')\n",
    "        self.wildfire_data['federal_subject'] =  self._predict_label(self.cities_data, self.wildfire_data, label='subject')\n",
    "        self.wildfire_data['district'] =  self._predict_label(self.cities_data, self.wildfire_data, label='district')\n",
    "        self.wildfire_data['population'] =  self._predict_label(self.cities_data, self.wildfire_data, label='population')\n",
    "        #Get minimum distance from fire incident to nature forest, forest, field, city\n",
    "        self.wildfire_data['nature_forest_dst'] = self._get_dst(self.nature_forest_data, self.wildfire_data)\n",
    "        self.wildfire_data['forest_dst'] = self._get_dst(self.forest_data, self.wildfire_data)\n",
    "        self.wildfire_data['field_dst'] = self._get_dst(self.field_data, self.wildfire_data)\n",
    "        self.wildfire_data['city_dst'] = self._get_dst(self.cities_data, self.wildfire_data)\n",
    "        #\n",
    "        self.wildfire_data = pd.concat([self.wildfire_data, \n",
    "                                        self._get_info_radius(self.forest_data, self.wildfire_data, [0.2, 0.5, 1.0], 'forest')], axis=1)\n",
    "        #\n",
    "        self.wildfire_data = pd.concat([self.wildfire_data, \n",
    "                                        self._get_info_radius(self.field_data, self.wildfire_data, [0.2, 0.5, 1.0], 'field')], axis=1)\n",
    "        #\n",
    "        self.wildfire_data = pd.concat([self.wildfire_data, \n",
    "                                        self._get_info_radius(self.cities_data, self.wildfire_data, [5, 10, 15], 'cities')], axis=1)\n",
    "        \n",
    "        #\n",
    "        self.wildfire_data = pd.concat([self.wildfire_data, \n",
    "                                        self._get_event_count_lastyear(self.wildfire_data)], axis=1)\n",
    "        #\n",
    "        #self.wildfire_data = pd.concat([self.wildfire_data, \n",
    "         #                               self._get_event_count_firetype(self.wildfire_data)], axis=1)\n",
    "\n",
    "        self.wildfire_data.to_csv(DATA_PATH + 'geo_features.csv', index=False)\n",
    "        end = time.time()\n",
    "        print(\"\\n\",\"=\"*5,\"Features Extraction has finished\",\"=\"*5)\n",
    "        print(\"Total time taken\", end-start, \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'load_Dataset' method to load the data into the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Dataset():\n",
    "    #wildfire\n",
    "    wildfire_data = pd.read_csv(DATA_PATH+'wildfires_train.csv', parse_dates=['date'])\n",
    "    #forest\n",
    "    forest_data = pd.read_csv(DATA_PATH+'additional/forest_coords.csv')\n",
    "    #field\n",
    "    field_data = pd.read_csv(DATA_PATH+'additional/field_coords.csv')\n",
    "    field_data['field'] = field_data['field'].apply(lambda x: 2)\n",
    "    #land data\n",
    "    land_data = pd.concat([forest_data.rename({'forest': 'land_type'}, axis=1),\n",
    "                           field_data.rename({'field': 'land_type'}, axis=1)]).reset_index(drop=True)\n",
    "    #nature\n",
    "    nature_forest_data = pd.read_csv(DATA_PATH+'additional/nature_forests.csv')\n",
    "    #cities\n",
    "    cities_data = pd.read_json(DATA_PATH+'additional/russian-cities.json')\n",
    "    cities_data = pd.concat([pd.json_normalize(cities_data.coords), cities_data], axis=1)\n",
    "    cities_data.drop('coords', axis=1, inplace=True)\n",
    "    cities_data.rename(columns={\"lat\": \"latitude\", \"lon\": \"longitude\"}, inplace=True)\n",
    "    cities_data['district'] = cities_data.district.astype('category').cat.codes\n",
    "    cities_data['subject'] = cities_data.subject.astype('category').cat.codes\n",
    "    return wildfire_data, forest_data, field_data, land_data, nature_forest_data, cities_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Geographical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Features Extraction has started =====\n",
      "\n",
      " ===== Features Extraction has finished =====\n",
      "Total time taken 83.87114191055298  sec\n"
     ]
    }
   ],
   "source": [
    "generator = GeographicalFeaturesGenerator(*load_Dataset())\n",
    "generator.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values in features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo_features = pd.read_csv(DATA_PATH + 'geo_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Pert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Count, Pert]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value = pd.DataFrame(df_geo_features.isnull().sum(axis=0), columns=['Count'])\n",
    "missing_value['Pert'] = missing_value.Count*100/df_geo_features.shape[0]\n",
    "missing_value.sort_values(by='Count', ascending=False, inplace=True)\n",
    "missing_value[missing_value.Count>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
